"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.createReactAgent = exports.createReactAgentAnnotation = void 0;
const messages_1 = require("@langchain/core/messages");
const runnables_1 = require("@langchain/core/runnables");
const index_js_1 = require("../graph/index.cjs");
const tool_node_js_1 = require("./tool_node.cjs");
const annotation_js_1 = require("../graph/annotation.cjs");
const message_js_1 = require("../graph/message.cjs");
const constants_js_1 = require("../constants.cjs");
function _convertMessageModifierToStateModifier(messageModifier) {
    // Handle string or SystemMessage
    if (typeof messageModifier === "string" ||
        ((0, messages_1.isBaseMessage)(messageModifier) && messageModifier._getType() === "system")) {
        return messageModifier;
    }
    // Handle callable function
    if (typeof messageModifier === "function") {
        return async (state) => messageModifier(state.messages);
    }
    // Handle Runnable
    if (runnables_1.Runnable.isRunnable(messageModifier)) {
        return runnables_1.RunnableLambda.from((state) => state.messages).pipe(messageModifier);
    }
    throw new Error(`Unexpected type for messageModifier: ${typeof messageModifier}`);
}
function _getStateModifierRunnable(stateModifier) {
    let stateModifierRunnable;
    if (stateModifier == null) {
        stateModifierRunnable = runnables_1.RunnableLambda.from((state) => state.messages).withConfig({ runName: "state_modifier" });
    }
    else if (typeof stateModifier === "string") {
        const systemMessage = new messages_1.SystemMessage(stateModifier);
        stateModifierRunnable = runnables_1.RunnableLambda.from((state) => {
            return [systemMessage, ...(state.messages ?? [])];
        }).withConfig({ runName: "state_modifier" });
    }
    else if ((0, messages_1.isBaseMessage)(stateModifier) &&
        stateModifier._getType() === "system") {
        stateModifierRunnable = runnables_1.RunnableLambda.from((state) => [
            stateModifier,
            ...state.messages,
        ]).withConfig({ runName: "state_modifier" });
    }
    else if (typeof stateModifier === "function") {
        stateModifierRunnable = runnables_1.RunnableLambda.from(stateModifier).withConfig({
            runName: "state_modifier",
        });
    }
    else if (runnables_1.Runnable.isRunnable(stateModifier)) {
        stateModifierRunnable = stateModifier;
    }
    else {
        throw new Error(`Got unexpected type for 'stateModifier': ${typeof stateModifier}`);
    }
    return stateModifierRunnable;
}
function _getModelPreprocessingRunnable(stateModifier, messageModifier) {
    // Check if both modifiers exist
    if (stateModifier != null && messageModifier != null) {
        throw new Error("Expected value for either stateModifier or messageModifier, got values for both");
    }
    // Convert message modifier to state modifier if necessary
    if (stateModifier == null && messageModifier != null) {
        // eslint-disable-next-line no-param-reassign
        stateModifier = _convertMessageModifierToStateModifier(messageModifier);
    }
    return _getStateModifierRunnable(stateModifier);
}
const createReactAgentAnnotation = () => annotation_js_1.Annotation.Root({
    messages: (0, annotation_js_1.Annotation)({
        reducer: message_js_1.messagesStateReducer,
        default: () => [],
    }),
    structuredResponse: (annotation_js_1.Annotation),
});
exports.createReactAgentAnnotation = createReactAgentAnnotation;
/**
 * Creates a StateGraph agent that relies on a chat model utilizing tool calling.
 *
 * @example
 * ```ts
 * import { ChatOpenAI } from "@langchain/openai";
 * import { tool } from "@langchain/core/tools";
 * import { z } from "zod";
 * import { createReactAgent } from "@langchain/langgraph/prebuilt";
 *
 * const model = new ChatOpenAI({
 *   model: "gpt-4o",
 * });
 *
 * const getWeather = tool((input) => {
 *   if (["sf", "san francisco"].includes(input.location.toLowerCase())) {
 *     return "It's 60 degrees and foggy.";
 *   } else {
 *     return "It's 90 degrees and sunny.";
 *   }
 * }, {
 *   name: "get_weather",
 *   description: "Call to get the current weather.",
 *   schema: z.object({
 *     location: z.string().describe("Location to get the weather for."),
 *   })
 * })
 *
 * const agent = createReactAgent({ llm: model, tools: [getWeather] });
 *
 * const inputs = {
 *   messages: [{ role: "user", content: "what is the weather in SF?" }],
 * };
 *
 * const stream = await agent.stream(inputs, { streamMode: "values" });
 *
 * for await (const { messages } of stream) {
 *   console.log(messages);
 * }
 * // Returns the messages in the state at each step of execution
 * ```
 */
function createReactAgent(params) {
    const { llm, tools, messageModifier, stateModifier, stateSchema, checkpointSaver, checkpointer, interruptBefore, interruptAfter, store, responseFormat, } = params;
    let toolClasses;
    if (!Array.isArray(tools)) {
        toolClasses = tools.tools;
    }
    else {
        toolClasses = tools;
    }
    if (!("bindTools" in llm) || typeof llm.bindTools !== "function") {
        throw new Error(`llm ${llm} must define bindTools method.`);
    }
    const modelWithTools = llm.bindTools(toolClasses);
    // we're passing store here for validation
    const preprocessor = _getModelPreprocessingRunnable(stateModifier, messageModifier);
    const modelRunnable = preprocessor.pipe(modelWithTools);
    // If any of the tools are configured to return_directly after running,
    // our graph needs to check if these were called
    const shouldReturnDirect = new Set(toolClasses
        .filter((tool) => "returnDirect" in tool && tool.returnDirect)
        .map((tool) => tool.name));
    const shouldContinue = (state) => {
        const { messages } = state;
        const lastMessage = messages[messages.length - 1];
        if ((0, messages_1.isAIMessage)(lastMessage) &&
            (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0)) {
            return responseFormat != null ? "generate_structured_response" : constants_js_1.END;
        }
        else {
            return "continue";
        }
    };
    const generateStructuredResponse = async (state, config) => {
        if (responseFormat == null) {
            throw new Error("Attempted to generate structured output with no passed response schema. Please contact us for help.");
        }
        // Exclude the last message as there's enough information
        // for the LLM to generate the structured response
        const messages = state.messages.slice(0, -1);
        let modelWithStructuredOutput;
        if (typeof responseFormat === "object" &&
            "prompt" in responseFormat &&
            "schema" in responseFormat) {
            const { prompt, schema } = responseFormat;
            modelWithStructuredOutput = llm.withStructuredOutput(schema);
            messages.unshift(new messages_1.SystemMessage({ content: prompt }));
        }
        else {
            modelWithStructuredOutput = llm.withStructuredOutput(responseFormat);
        }
        const response = await modelWithStructuredOutput.invoke(messages, config);
        return { structuredResponse: response };
    };
    const callModel = async (state, config) => {
        // TODO: Auto-promote streaming.
        return { messages: [await modelRunnable.invoke(state, config)] };
    };
    const workflow = new index_js_1.StateGraph(stateSchema ?? (0, exports.createReactAgentAnnotation)())
        .addNode("agent", callModel)
        .addNode("tools", new tool_node_js_1.ToolNode(toolClasses))
        .addEdge(constants_js_1.START, "agent");
    if (responseFormat !== undefined) {
        workflow
            .addNode("generate_structured_response", generateStructuredResponse)
            .addEdge("generate_structured_response", constants_js_1.END)
            .addConditionalEdges("agent", shouldContinue, {
            continue: "tools",
            [constants_js_1.END]: constants_js_1.END,
            generate_structured_response: "generate_structured_response",
        });
    }
    else {
        workflow.addConditionalEdges("agent", shouldContinue, {
            continue: "tools",
            [constants_js_1.END]: constants_js_1.END,
        });
    }
    const routeToolResponses = (state) => {
        // Check the last consecutive tool calls
        for (let i = state.messages.length - 1; i >= 0; i -= 1) {
            const message = state.messages[i];
            if (!(0, messages_1.isToolMessage)(message)) {
                break;
            }
            // Check if this tool is configured to return directly
            if (message.name !== undefined && shouldReturnDirect.has(message.name)) {
                return constants_js_1.END;
            }
        }
        return "agent";
    };
    if (shouldReturnDirect.size > 0) {
        workflow.addConditionalEdges("tools", routeToolResponses, ["agent", constants_js_1.END]);
    }
    else {
        workflow.addEdge("tools", "agent");
    }
    return workflow.compile({
        checkpointer: checkpointer ?? checkpointSaver,
        interruptBefore,
        interruptAfter,
        store,
    });
}
exports.createReactAgent = createReactAgent;
